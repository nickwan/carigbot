{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hello\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, TimeDistributed, LSTM, CuDNNLSTM\n",
    "from keras.optimizers import RMSprop\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_cleaner(row):\n",
    "    word_list = [word for word in row.split(' ') if (len(word)>0) and (word[0] != '@') and (word[:4] != 'http') and (word != 'rt')]\n",
    "    return ' '.join(word_list)\n",
    "\n",
    "def create_index_char_map(corpus):\n",
    "    chars = sorted(list(set(corpus)))\n",
    "    global N_CHARS\n",
    "    N_CHARS = len(chars)\n",
    "    char_to_idx = {c: i for i, c in enumerate(chars)}\n",
    "    idx_to_char = {i: c for i, c in enumerate(chars)}\n",
    "    return chars, char_to_idx, idx_to_char\n",
    "\n",
    "def create_sequences(corpus):\n",
    "    sequences, next_chars = [], []\n",
    "    for i in range(0, CORPUS_LENGTH - MAX_SEQ_LENGTH, SEQ_STEP):\n",
    "        sequences.append(corpus[i:i + MAX_SEQ_LENGTH])\n",
    "        next_chars.append(corpus[i + MAX_SEQ_LENGTH])\n",
    "    global N_SEQS\n",
    "    N_SEQS = len(sequences)\n",
    "    return np.array(sequences), np.array(next_chars)\n",
    "\n",
    "def one_hot_encode(sequences, next_chars, char_to_idx):\n",
    "    X = np.zeros((N_SEQS, MAX_SEQ_LENGTH, N_CHARS), dtype=np.bool)\n",
    "    y = np.zeros((N_SEQS, N_CHARS), dtype=np.bool)\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        for t, char in enumerate(sequence):\n",
    "            X[i, t, char_to_idx[char]] = 1\n",
    "    y[i, char_to_idx[next_chars[i]]] = 1\n",
    "    return X, y\n",
    "\n",
    "def load_data(data, seq_length):\n",
    "    chars = list(set(data))\n",
    "    VOCAB_SIZE = len(chars)\n",
    "\n",
    "    print('Data length: {} characters'.format(len(data)))\n",
    "    print('Vocabulary size: {} characters'.format(VOCAB_SIZE))\n",
    "\n",
    "    ix_to_char = {ix:char for ix, char in enumerate(chars)}\n",
    "    char_to_ix = {char:ix for ix, char in enumerate(chars)}\n",
    "\n",
    "    X = np.zeros((int(len(data)/seq_length), seq_length, VOCAB_SIZE))\n",
    "    y = np.zeros((int(len(data)/seq_length), seq_length, VOCAB_SIZE))\n",
    "    for i in range(0, int(len(data)/seq_length)):\n",
    "        X_sequence = data[i*seq_length:(i+1)*seq_length]\n",
    "        X_sequence_ix = [char_to_ix[value] for value in X_sequence]\n",
    "        input_sequence = np.zeros((seq_length, VOCAB_SIZE))\n",
    "        for j in range(seq_length):\n",
    "            input_sequence[j][X_sequence_ix[j]] = 1.\n",
    "            X[i] = input_sequence\n",
    "\n",
    "        y_sequence = data[i*seq_length+1:(i+1)*seq_length+1]\n",
    "        y_sequence_ix = [char_to_ix[value] for value in y_sequence]\n",
    "        target_sequence = np.zeros((seq_length, VOCAB_SIZE))\n",
    "        for j in range(seq_length):\n",
    "            target_sequence[j][y_sequence_ix[j]] = 1.\n",
    "            y[i] = target_sequence\n",
    "    return X, y, VOCAB_SIZE, ix_to_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/marccarig_tweets.csv').dropna(subset=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>id_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>TweetDeck</td>\n",
       "      <td>Shadows are going to make this game interestin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Sun Oct 02 19:21:28 +0000 2011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.210000e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>Markakis almost smokes Vazquez in the dugout. ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Wed Apr 28 00:59:08 +0000 2010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.297676e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>If Rivera indeed gets a chance at save No. 500...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Mon Jun 29 02:56:18 +0000 2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.381677e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Echofon</td>\n",
       "      <td>@jeffzrebiecsun they are scrumptious</td>\n",
       "      <td>jeffzrebiecsun</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Mar 19 14:07:11 +0000 2013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.140000e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>RT @dp57: At halloween store yesterday with my...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 13 11:49:29 +0000 2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.833040e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   favorite_count              source  \\\n",
       "1             0.0           TweetDeck   \n",
       "3             0.0  Twitter Web Client   \n",
       "5             0.0  Twitter Web Client   \n",
       "7             0.0             Echofon   \n",
       "9             0.0  Twitter Web Client   \n",
       "\n",
       "                                                text in_reply_to_screen_name  \\\n",
       "1  Shadows are going to make this game interestin...                     NaN   \n",
       "3  Markakis almost smokes Vazquez in the dugout. ...                     NaN   \n",
       "5  If Rivera indeed gets a chance at save No. 500...                     NaN   \n",
       "7               @jeffzrebiecsun they are scrumptious          jeffzrebiecsun   \n",
       "9  RT @dp57: At halloween store yesterday with my...                     NaN   \n",
       "\n",
       "  is_retweet                      created_at  retweet_count        id_str  \n",
       "1      False  Sun Oct 02 19:21:28 +0000 2011            0.0  1.210000e+17  \n",
       "3      False  Wed Apr 28 00:59:08 +0000 2010            0.0  1.297676e+10  \n",
       "5      False  Mon Jun 29 02:56:18 +0000 2009            0.0  2.381677e+09  \n",
       "7      False  Tue Mar 19 14:07:11 +0000 2013            0.0  3.140000e+17  \n",
       "9      False  Tue Oct 13 11:49:29 +0000 2009            0.0  4.833040e+09  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text = df['text'].str.lower()\n",
    "text = text.loc[~text.str.startswith('rt @')]\n",
    "text = text.apply(text_cleaner)\n",
    "text = text.sample(25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87379     you guys are all over the place on nova predic...\n",
       "68431     talked to marlon byrd about steroids this morn...\n",
       "136227    unlike my portfolio, i find this to be strong ...\n",
       "42729     yankees notebook: andy pettitte feeling fine a...\n",
       "145049    the yankees this week: home runs help team get...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "things_to_take_out = ['\\x80','\\x9c','\\xa0', '¡','®','°','·','à','á','â','è','é', '\\'', '\\r', '\\n', '\\t',\n",
    "                      'ê','í','ñ','ó','̶','\\u200d','\\u200f','–','—','‘','’','“','”','…','‼','⁉','≤','、',\n",
    "                      'い','う','き','し','ち','っ','て','に','の','は','ょ','る','を','ウ','ク','サ','ス',\n",
    "                      'ビ','ブ','ベ','ロ','ン','ー','取','才','断','決','私','能','️','🇦','🇨','🇮','🇰','🇳','🇵','🇷','🇸',\n",
    "                      '🇹','🇺','\\U0001f951','\\U0001f985','\\U0001f9e0', '\\\\']\n",
    "\n",
    "corpus = [tweet for tweet in text.values]\n",
    "corpus = ' '.join(corpus)\n",
    "\n",
    "for char in things_to_take_out:\n",
    "    corpus = corpus.replace(char, '')\n",
    "    \n",
    "corpus = corpus.replace('--', '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1610509\n",
      "you guys are all over the place on nova predictions. talked to marlon byrd about steroids this morni\n"
     ]
    }
   ],
   "source": [
    "print(len(corpus))\n",
    "print(corpus[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/',\n",
       " '9',\n",
       " '🎂',\n",
       " 'p',\n",
       " '%',\n",
       " '🌴',\n",
       " 'm',\n",
       " 'j',\n",
       " '_',\n",
       " '=',\n",
       " '8',\n",
       " 'z',\n",
       " '😍',\n",
       " 'l',\n",
       " ')',\n",
       " '🏡',\n",
       " '🎁',\n",
       " '🐮',\n",
       " '|',\n",
       " '&',\n",
       " 'q',\n",
       " '-',\n",
       " '😎',\n",
       " '💯',\n",
       " 'c',\n",
       " '!',\n",
       " 'y',\n",
       " ';',\n",
       " '🎈',\n",
       " '♥',\n",
       " '🏕',\n",
       " '#',\n",
       " '❤',\n",
       " '~',\n",
       " '@',\n",
       " 'g',\n",
       " ':',\n",
       " 'o',\n",
       " '6',\n",
       " '🗽',\n",
       " '1',\n",
       " 's',\n",
       " 'w',\n",
       " ']',\n",
       " '🎣',\n",
       " '☕',\n",
       " 'k',\n",
       " '🐟',\n",
       " '+',\n",
       " '🍴',\n",
       " '[',\n",
       " '(',\n",
       " '3',\n",
       " '😂',\n",
       " 'a',\n",
       " '😢',\n",
       " 'e',\n",
       " '^',\n",
       " '😄',\n",
       " 'd',\n",
       " '👀',\n",
       " 'b',\n",
       " '$',\n",
       " '💔',\n",
       " '5',\n",
       " 't',\n",
       " '😀',\n",
       " '🎉',\n",
       " '😬',\n",
       " '🍺',\n",
       " '?',\n",
       " '😳',\n",
       " '4',\n",
       " '7',\n",
       " 'x',\n",
       " '🙌',\n",
       " 'f',\n",
       " '2',\n",
       " ' ',\n",
       " '🤔',\n",
       " '\"',\n",
       " '.',\n",
       " 'n',\n",
       " '*',\n",
       " '🐷',\n",
       " '0',\n",
       " '😥',\n",
       " '😒',\n",
       " '😱',\n",
       " '⛳',\n",
       " '☀',\n",
       " ',',\n",
       " '💀',\n",
       " 'i',\n",
       " '😡',\n",
       " '🏞',\n",
       " '`',\n",
       " '✨',\n",
       " 'h',\n",
       " 'v',\n",
       " 'r',\n",
       " '⚾',\n",
       " '😭',\n",
       " 'u']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data length: 1610509 characters\n",
      "Vocabulary size: 105 characters\n"
     ]
    }
   ],
   "source": [
    "X, y, VOCAB_SIZE, ix_to_char = load_data(corpus, 85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/idx_to_char', 'wb') as fp:\n",
    "    pickle.dump(ix_to_char, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, None, 512)         1265664   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, None, 512)         0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, None, 512)         2099200   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, None, 512)         0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, None, 512)         2099200   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, None, 512)         0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, None, 105)         53865     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, None, 105)         0         \n",
      "=================================================================\n",
      "Total params: 5,517,929\n",
      "Trainable params: 5,517,929\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(HIDDEN_DIM=512, dropout=0.3, LAYER_NUM=3):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(HIDDEN_DIM, input_shape=(None, VOCAB_SIZE), return_sequences=True))\n",
    "    model.add(Dropout(dropout))\n",
    "    for i in range(LAYER_NUM - 1):\n",
    "        model.add(LSTM(HIDDEN_DIM, return_sequences=True))\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(TimeDistributed(Dense(VOCAB_SIZE)))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, X, y, batch_size=128, nb_epoch=5000, verbose=0):\n",
    "    checkpointer = ModelCheckpoint(filepath=\"models/v01weights_{epoch:02d}.hdf5\", monitor='loss', verbose=verbose, save_best_only=True, mode='min')\n",
    "    model.fit(X, y, batch_size=batch_size, epochs=nb_epoch, verbose=verbose, callbacks=[checkpointer])\n",
    "    \n",
    "train_model(model, X, y, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
